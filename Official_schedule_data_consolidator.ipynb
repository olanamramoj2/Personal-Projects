{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "history_visible": true,
      "mount_file_id": "1DkGJvPw_4JVduDqW6qVPTVU-dUAe-U8c",
      "authorship_tag": "ABX9TyM/lbH1CzlJt6IiTJkGjkpT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/olanamramoj2/Personal-Projects/blob/main/Official_schedule_data_consolidator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GMv1cU94V3Yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmhSXyq3KFXv",
        "outputId": "b48fa968-7147-4096-d560-098931026d3c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n",
            "WARNING:google_auth_httplib2:httplib2 transport does not support per-request timeout. Set the timeout when constructing the httplib2.Http instance.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "ðŸš€ STARTING PROCESS FOR: QUEZON CITY\n",
            "  Found 14 total spreadsheets in Quezon City hierarchy.\n",
            "    âœ… Read: SMPW 2026 Availability - LRT 2 V. Mapa (Responses)\n",
            "    âœ… Read: SMPW 2026 Availability - BIR Fisher Mall (Responses)\n",
            "    âœ… Read: SMPW 2026 Availability - LTO Central Office (Responses)\n",
            "    âœ… Read: SMPW 2026 Availability - SSS Diliman (Responses)\n",
            "    âœ… Read: SMPW 2026 Availability - Quezon Memorial Circle (Responses)\n",
            "    âœ… Read: SMPW 2026 Availability - LRT2 Araneta Gateway (Responses)\n",
            "    âœ… Read: SMPW 2026 Availability - LRT Gilmore (Responses)\n",
            "    âœ… Read: SMPW 2026 Availability - Philippine Orthopedic Center (Responses)\n",
            "    âœ… Read:  SMPW 2026 Availability - NHA/ Maharlika (Responses)\n",
            "    âœ… Read: SMPW 2026 Availability - LRT 2 Cubao - Diamond Arcade (Responses)\n",
            "    âœ… Read: SMPW 2026 Availability - NBI Quezon City (Responses)\n",
            "    âœ… Read: SMPW 2026 Availability - Florida Bus Station QC (Responses)\n",
            "    âœ… Read: SMPW 2026 Availability - National Kidney and Transplant Institute (Responses)\n",
            "    âœ… Read: SMPW 2026 Availability - Bureau of Immigration QC  (Responses)\n",
            "ðŸ’¾ File Saved in: SMPW East Zone Volunteer Availability Data/Quezon City_combined_open_records.xlsx\n",
            "\n",
            "ðŸš€ STARTING PROCESS FOR: SAN JUAN\n",
            "  Found 4 total spreadsheets in San Juan hierarchy.\n",
            "    âœ… Read: SMPW Availability - San Juan City Hall and Pinaglabanan Shrine (Responses)\n",
            "    âœ… Read: SMPW Availability - Puregold Agora San Juan (Responses)\n",
            "    âœ… Read: SMPW Availability - LTO San Juan (Responses)\n",
            "    âœ… Read: SMPW Availability - LTO N. Domingo (Responses)\n",
            "\n",
            "ðŸš€ STARTING PROCESS FOR: PASIG\n",
            "  Found 7 total spreadsheets in Pasig hierarchy.\n",
            "    âœ… Read: SMPW 2026 Availability - Eastern Police District (Pasig) (Responses)\n",
            "    âœ… Read: SMPW 2026 Availability - Pineda (Across RMC) (Responses)\n",
            "    âœ… Read: SMPW 2026 Availability - Rizal High School (Responses)\n",
            "    âœ… Read: SMPW 2026 Availability - Pasig Mega Market (Responses)\n",
            "    âœ… Read: Copy of SMPW 2026 Availability - Pasig Mega Market (Responses)\n",
            "    âœ… Read: SMPW 2026 Availability - Crossing (Responses)\n",
            "\n",
            "ðŸš€ STARTING PROCESS FOR: MANDALUYONG\n",
            "  Found 4 total spreadsheets in Mandaluyong hierarchy.\n",
            "    âœ… Read: SMPW 2026 Availability - EDSA Shaw Blvd (Responses)\n",
            "    âœ… Read: SMPW 2026 Availability - Maysilo Circle (Responses)\n",
            "    âœ… Read: SMPW 2026 Availability - EDSA Pioneer Woodlands (Responses)\n",
            "    âœ… Read: SMPW 2026 Availability - Department of Migrant Workers (Formerly POEA) (Responses)\n",
            "ðŸ’¾ File Saved in: SMPW East Zone Volunteer Availability Data/Mandaluyong_combined_open_records.xlsx\n",
            "\n",
            "âœ¨ All cities and subfolders processed!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from google.colab import drive, auth\n",
        "import gspread\n",
        "from google.auth import default\n",
        "from googleapiclient.discovery import build\n",
        "import time\n",
        "\n",
        "# 1. Authenticate\n",
        "auth.authenticate_user()\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)\n",
        "drive_service = build('drive', 'v3', credentials=creds)\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "PARENT_FOLDER_NAME = \"SMPW East Zone Volunteer Availability Data\"\n",
        "CITY_LIST = [\"Quezon City\", \"San Juan\", \"Pasig\", \"Mandaluyong\"]\n",
        "TARGET_SHEET_NAME = \"Form Responses 1\"\n",
        "OUTPUT_COLUMNS = [\"first name\", \"last name\", \"contact number\", \"gender\", \"date of duty\", \"preferred shift\", \"status\", \"location\"]\n",
        "UNIQUE_KEYS = [\"first name\", \"last name\", \"date of duty\", \"preferred shift\", \"location\"]\n",
        "MAX_RETRIES = 3\n",
        "\n",
        "# --- HELPER FUNCTION FOR RECURSIVE SEARCH ---\n",
        "def get_all_sheets_in_folder_recursive(folder_id):\n",
        "    \"\"\"Finds all Google Sheets within a folder and all its subfolders.\"\"\"\n",
        "    all_sheets = []\n",
        "\n",
        "    # 1. Get all Google Sheets in the current folder\n",
        "    query = f\"'{folder_id}' in parents and mimeType = 'application/vnd.google-apps.spreadsheet' and trashed = false\"\n",
        "    results = drive_service.files().list(q=query, fields=\"files(id, name)\").execute()\n",
        "    all_sheets.extend(results.get('files', []))\n",
        "\n",
        "    # 2. Find all subfolders\n",
        "    subfolder_query = f\"'{folder_id}' in parents and mimeType = 'application/vnd.google-apps.folder' and trashed = false\"\n",
        "    subfolder_results = drive_service.files().list(q=subfolder_query, fields=\"files(id)\").execute()\n",
        "    subfolders = subfolder_results.get('files', [])\n",
        "\n",
        "    # 3. Recursively search each subfolder\n",
        "    for sf in subfolders:\n",
        "        all_sheets.extend(get_all_sheets_in_folder_recursive(sf['id']))\n",
        "\n",
        "    return all_sheets\n",
        "\n",
        "# 3. Get Parent Folder ID\n",
        "folder_query = f\"name = '{PARENT_FOLDER_NAME}' and mimeType = 'application/vnd.google-apps.folder' and trashed = false\"\n",
        "folder_results = drive_service.files().list(q=folder_query, fields=\"files(id)\").execute()\n",
        "files_found = folder_results.get('files', [])\n",
        "\n",
        "if not files_found:\n",
        "    print(f\"âŒ Could not find folder: {PARENT_FOLDER_NAME}\")\n",
        "else:\n",
        "    PARENT_FOLDER_ID = files_found[0].get('id')\n",
        "\n",
        "    # 4. Main Loop\n",
        "    for city in CITY_LIST:\n",
        "        print(f\"\\nðŸš€ STARTING PROCESS FOR: {city.upper()}\")\n",
        "        city_data = []\n",
        "\n",
        "        # Find the City Subfolder ID\n",
        "        city_folder_query = f\"'{PARENT_FOLDER_ID}' in parents and name = '{city}' and mimeType = 'application/vnd.google-apps.folder' and trashed = false\"\n",
        "        city_folder_res = drive_service.files().list(q=city_folder_query, fields=\"files(id)\").execute()\n",
        "        city_folders = city_folder_res.get('files')\n",
        "\n",
        "        if not city_folders:\n",
        "            print(f\"âš ï¸ City folder '{city}' not found.\")\n",
        "            continue\n",
        "\n",
        "        city_id = city_folders[0].get('id')\n",
        "\n",
        "        # NEW: Get all sheets from City folder AND its subfolders\n",
        "        all_city_sheets = get_all_sheets_in_folder_recursive(city_id)\n",
        "        print(f\"  Found {len(all_city_sheets)} total spreadsheets in {city} hierarchy.\")\n",
        "\n",
        "        for sheet_info in all_city_sheets:\n",
        "            file_id = sheet_info['id']\n",
        "            file_name = sheet_info['name']\n",
        "\n",
        "            # Location extraction\n",
        "            filename_without_ext = os.path.splitext(file_name)[0]\n",
        "            parts = filename_without_ext.split(' - ', 1)\n",
        "            location = parts[1].strip() if len(parts) > 1 else filename_without_ext\n",
        "            location = location.replace(\" (Responses)\", \"\")\n",
        "\n",
        "            attempts = 0\n",
        "            success = False\n",
        "            while attempts < MAX_RETRIES and not success:\n",
        "                try:\n",
        "                    sh = gc.open_by_key(file_id)\n",
        "                    try:\n",
        "                        worksheet = sh.worksheet(TARGET_SHEET_NAME)\n",
        "                    except gspread.exceptions.WorksheetNotFound:\n",
        "                        success = True # Skip silently if tab doesn't exist\n",
        "                        continue\n",
        "\n",
        "                    data = worksheet.get_all_records()\n",
        "                    df = pd.DataFrame(data)\n",
        "\n",
        "                    if not df.empty:\n",
        "                        df.columns = df.columns.str.strip().str.lower()\n",
        "                        if 'status' in df.columns:\n",
        "                            status_col = df[\"status\"].astype(str).str.strip().str.lower()\n",
        "                            # open_rows = df[(status_col == \"open\") | (status_col == \"\")].copy()\n",
        "                            open_rows = df[(status_col == \"open\")].copy()\n",
        "\n",
        "                            if not open_rows.empty:\n",
        "                                open_rows[\"location\"] = location\n",
        "                                existing_cols = [c for c in OUTPUT_COLUMNS if c in open_rows.columns]\n",
        "                                city_data.append(open_rows[existing_cols])\n",
        "\n",
        "                    success = True\n",
        "                    print(f\"    âœ… Read: {file_name}\")\n",
        "\n",
        "                except Exception as e:\n",
        "                    attempts += 1\n",
        "                    if attempts < MAX_RETRIES:\n",
        "                        time.sleep(3)\n",
        "                    else:\n",
        "                        print(f\"    âŒ [Failed] {file_name}: {e}\")\n",
        "\n",
        "        # --- SAVE CITY OUTPUT ---\n",
        "        if city_data:\n",
        "            new_df = pd.concat(city_data, ignore_index=True)\n",
        "            new_df = new_df.drop_duplicates(subset=[k for k in UNIQUE_KEYS if k in new_df.columns], keep=\"last\")\n",
        "\n",
        "            clean_city_name = city.replace('/', '_')\n",
        "            output_filename = f\"/content/drive/MyDrive/Colab Notebooks/Schedule consolidator/{PARENT_FOLDER_NAME}/{clean_city_name}_combined_open_records.xlsx\"\n",
        "            new_df.to_excel(output_filename, index=False)\n",
        "            print(f\"ðŸ’¾ File Saved in: {PARENT_FOLDER_NAME}/{clean_city_name}_combined_open_records.xlsx\")\n",
        "\n",
        "print(\"\\nâœ¨ All cities and subfolders processed!\")"
      ]
    }
  ]
}